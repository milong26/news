"""
pip install pupil_apriltags
pip install scipy
"""

import torch
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from pupil_apriltags import Detector
from lerobot.datasets.lerobot_dataset import LeRobotDataset
from scipy.spatial.transform import Rotation as R
import traceback
import sys
import gc


def get_intrinsics():
    """è·å–ç›¸æœºå†…å‚"""
    import pyrealsense2 as rs

    pipeline = rs.pipeline()
    config = rs.config()

    config.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)
    config.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)

    profile = pipeline.start(config)

    color_stream = profile.get_stream(rs.stream.color)
    intr = color_stream.as_video_stream_profile().get_intrinsics()

    camera_intrinsics = {
        "fx": intr.fx,
        "fy": intr.fy,
        "cx": intr.ppx,
        "cy": intr.ppy
    }
    
    pipeline.stop()
    
    print(f"âœ“ ç›¸æœºå†…å‚: fx={camera_intrinsics['fx']:.2f}, fy={camera_intrinsics['fy']:.2f}, "
          f"cx={camera_intrinsics['cx']:.2f}, cy={camera_intrinsics['cy']:.2f}")
    
    return camera_intrinsics


def state_to_matrix(state):
    """
    å°†çŠ¶æ€å‘é‡è½¬æ¢ä¸º4x4å˜æ¢çŸ©é˜µ
    state: [x, y, z, qx, qy, qz, qw]
    """
    pos = state[:3]
    quat = state[3:7]
    
    # æ£€æŸ¥å››å…ƒæ•°æ˜¯å¦æœ‰æ•ˆ
    quat_norm = np.linalg.norm(quat)
    if quat_norm < 0.01:
        raise ValueError(f"å››å…ƒæ•°èŒƒæ•°è¿‡å°: {quat_norm}")
    
    # å½’ä¸€åŒ–å››å…ƒæ•°
    quat = quat / quat_norm
    
    rot = R.from_quat(quat).as_matrix()

    T = np.eye(4)
    T[:3, :3] = rot
    T[:3, 3] = pos
    return T


def detect_apriltag_pose(
    image,
    detector,
    tag_size=0.02,
    tag_id=0,
    camera_intrinsics=None,
    max_z_cos=0.97,
    min_decision_margin=50
):
    """
    æ£€æµ‹AprilTagå¹¶è¿”å›ä½å§¿
    
    è¿”å›:
        T_cam_tag (4x4 numpy array) æˆ– None
    """
    # è½¬æ¢ä¸ºç°åº¦å›¾
    if isinstance(image, Image.Image):
        gray = np.array(image.convert("L"))
    else:
        gray = np.array(Image.fromarray(image).convert("L"))

    # æ£€æŸ¥å›¾åƒå°ºå¯¸
    if gray.shape[0] == 0 or gray.shape[1] == 0:
        return None

    fx = camera_intrinsics["fx"]
    fy = camera_intrinsics["fy"]
    cx = camera_intrinsics["cx"]
    cy = camera_intrinsics["cy"]

    # æ£€æµ‹AprilTag
    detections = detector.detect(
        gray,
        estimate_tag_pose=True,
        camera_params=[fx, fy, cx, cy],
        tag_size=tag_size
    )

    # æŸ¥æ‰¾ç›®æ ‡tag
    for det in detections:
        if det.tag_id != tag_id:
            continue

        # è´¨é‡æ£€æŸ¥
        if det.hamming > 0:
            return None
            
        if det.decision_margin < min_decision_margin:
            return None

        # æ³•å‘é‡æ£€æŸ¥(é¿å…é€€åŒ–è§†è§’)
        z_cam = det.pose_R[:, 2]
        if abs(z_cam[2]) > max_z_cos:
            return None

        # æ„å»ºå˜æ¢çŸ©é˜µ
        T = np.eye(4)
        T[:3, :3] = det.pose_R
        T[:3, 3] = det.pose_t.squeeze()
        
        return T

    return None


def process_batch(
    dataset,
    start_idx,
    end_idx,
    image_key,
    state_key,
    camera_intrinsics,
    tag_size,
    tag_id,
    T_tag_ee
):
    """
    å¤„ç†ä¸€æ‰¹æ•°æ®
    
    è¿”å›:
        batch_Ts: è¯¥æ‰¹æ¬¡çš„æœ‰æ•ˆå˜æ¢çŸ©é˜µåˆ—è¡¨
        valid_count: æœ‰æ•ˆå¸§æ•°
    """
    # åˆ›å»ºæ£€æµ‹å™¨(æ¯æ‰¹éƒ½åˆ›å»ºæ–°çš„)
    detector = Detector(
        families="tag36h11",
        nthreads=1,
        quad_decimate=1.0,
        quad_sigma=0.0,
        refine_edges=1,
        decode_sharpening=0.25,
        debug=0
    )
    
    batch_Ts = []
    valid_count = 0
    
    try:
        for idx in range(start_idx, end_idx):
            if idx >= len(dataset):
                break
                
            try:
                # è·å–æ•°æ®
                item = dataset[idx]
                
                # è·å–å›¾åƒ
                img = item[image_key]
                if isinstance(img, torch.Tensor):
                    img = img.permute(1, 2, 0).numpy()
                    if img.max() <= 1:
                        img = (img * 255).astype(np.uint8)
                    else:
                        img = img.astype(np.uint8)
                    img = Image.fromarray(img)
                elif not isinstance(img, Image.Image):
                    img = Image.fromarray(np.array(img).astype(np.uint8))
                
                # è·å–çŠ¶æ€
                state = item[state_key]
                if isinstance(state, torch.Tensor):
                    state = state.numpy()
                state = np.array(state, dtype=np.float64)
                
                if len(state) < 7:
                    continue
                
                # è½¬æ¢ä¸ºå˜æ¢çŸ©é˜µ
                T_ee_base = state_to_matrix(state)
                
                # æ£€æµ‹AprilTag
                T_cam_tag = detect_apriltag_pose(
                    img,
                    detector,
                    tag_size=tag_size,
                    tag_id=tag_id,
                    camera_intrinsics=camera_intrinsics
                )
                
                if T_cam_tag is None:
                    continue
                
                # è®¡ç®—T_cam_base
                T_cam_base = T_cam_tag @ np.linalg.inv(T_tag_ee) @ np.linalg.inv(T_ee_base)
                
                # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰æ•ˆ
                if np.any(np.isnan(T_cam_base)) or np.any(np.isinf(T_cam_base)):
                    continue
                
                batch_Ts.append(T_cam_base)
                valid_count += 1
                
                # ç®€æ´è¾“å‡º
                if (idx - start_idx + 1) % 50 == 0:
                    print(f"  è¿›åº¦: {idx - start_idx + 1}/{end_idx - start_idx}, æœ‰æ•ˆ: {valid_count}")
                    sys.stdout.flush()
                
            except Exception as e:
                # å•å¸§é”™è¯¯ä¸å½±å“å…¶ä»–å¸§
                continue
                
    finally:
        # ç¡®ä¿æ£€æµ‹å™¨è¢«åˆ é™¤
        del detector
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
    
    return batch_Ts, valid_count


def process_dataset(
    repo_id,
    image_key="observation.images.side",
    state_key="observation.state",
    tag_size=0.02,
    tag_id=0,
    T_tag_ee=None,
    batch_size=500
):
    """
    æ‰¹é‡å¤„ç†æ•°æ®é›†å¹¶è®¡ç®—æ‰‹çœ¼æ ‡å®šçŸ©é˜µ
    
    å‚æ•°:
        repo_id: æ•°æ®é›†è·¯å¾„
        image_key: å›¾åƒæ•°æ®çš„é”®
        state_key: çŠ¶æ€æ•°æ®çš„é”®
        tag_size: AprilTagå°ºå¯¸(ç±³)
        tag_id: AprilTag ID
        T_tag_ee: tagåˆ°æœ«ç«¯æ‰§è¡Œå™¨çš„å›ºå®šå˜æ¢(4x4çŸ©é˜µ)
        batch_size: æ¯æ‰¹å¤„ç†çš„å¸§æ•°
    
    è¿”å›:
        Ts: æ‰€æœ‰æœ‰æ•ˆçš„T_cam_eeçŸ©é˜µ
    """
    # åŠ è½½æ•°æ®é›†
    print(f"\næ­£åœ¨åŠ è½½æ•°æ®é›†: {repo_id}")
    try:
        dataset = LeRobotDataset(repo_id=repo_id, download_videos=False)
        print(f"âœ“ æ•°æ®é›†åŠ è½½å®Œæˆ,å…± {len(dataset)} å¸§")
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        traceback.print_exc()
        return None

    # è·å–ç›¸æœºå†…å‚
    try:
        camera_intrinsics = get_intrinsics()
    except Exception as e:
        print(f"âŒ è·å–ç›¸æœºå†…å‚å¤±è´¥: {e}")
        traceback.print_exc()
        return None

    # é»˜è®¤T_tag_eeä¸ºå•ä½çŸ©é˜µ
    if T_tag_ee is None:
        T_tag_ee = np.eye(4)
        print("âš  ä½¿ç”¨é»˜è®¤T_tag_ee(å•ä½çŸ©é˜µ),è¯·æ ¹æ®å®é™…å®‰è£…ä¿®æ”¹")

    # è®¡ç®—æ‰¹æ¬¡æ•°
    total_frames = len(dataset)
    num_batches = (total_frames + batch_size - 1) // batch_size
    
    print(f"\nå¼€å§‹æ‰¹é‡å¤„ç†:")
    print(f"  æ€»å¸§æ•°: {total_frames}")
    print(f"  æ‰¹æ¬¡å¤§å°: {batch_size}")
    print(f"  æ‰¹æ¬¡æ•°é‡: {num_batches}")
    print("=" * 60)

    all_Ts = []
    total_valid = 0
    
    # é€æ‰¹å¤„ç†
    for batch_idx in range(num_batches):
        start_idx = batch_idx * batch_size
        end_idx = min((batch_idx + 1) * batch_size, total_frames)
        
        print(f"\nğŸ“¦ æ‰¹æ¬¡ {batch_idx + 1}/{num_batches}")
        print(f"   å¤„ç†å¸§: {start_idx} - {end_idx - 1}")
        
        try:
            batch_Ts, valid_count = process_batch(
                dataset=dataset,
                start_idx=start_idx,
                end_idx=end_idx,
                image_key=image_key,
                state_key=state_key,
                camera_intrinsics=camera_intrinsics,
                tag_size=tag_size,
                tag_id=tag_id,
                T_tag_ee=T_tag_ee
            )
            
            all_Ts.extend(batch_Ts)
            total_valid += valid_count
            
            print(f"   âœ“ æœ¬æ‰¹æœ‰æ•ˆ: {valid_count}/{end_idx - start_idx}")
            print(f"   ç´¯è®¡æœ‰æ•ˆ: {total_valid}/{end_idx}")
            
            # æ˜¾å¼é‡Šæ”¾å†…å­˜
            del batch_Ts
            gc.collect()
            
        except KeyboardInterrupt:
            print("\n\nâš  ç”¨æˆ·ä¸­æ–­")
            break
        except Exception as e:
            print(f"   âœ— æ‰¹æ¬¡å¤„ç†å¤±è´¥: {e}")
            traceback.print_exc()
            continue

    print("\n" + "=" * 60)
    print(f"âœ“ å…¨éƒ¨å¤„ç†å®Œæˆ: {total_valid}/{total_frames} å¸§æœ‰æ•ˆ ({100*total_valid/total_frames:.1f}%)")
    print("=" * 60 + "\n")
    
    if total_valid == 0:
        return None
    
    return np.stack(all_Ts)


def visualize_results(Ts):
    """å¯è§†åŒ–æ ‡å®šç»“æœ"""
    if Ts is None or len(Ts) == 0:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®,æ— æ³•ç»˜å›¾")
        return

    print(f"æ­£åœ¨ç»˜åˆ¶ {len(Ts)} ä¸ªæœ‰æ•ˆæ ‡å®šçŸ©é˜µ...")
    
    try:
        # è®¡ç®—å¹³å‡å€¼å’Œæ ‡å‡†å·®
        T_mean = Ts.mean(axis=0)
        T_std = Ts.std(axis=0)

        # ç»˜åˆ¶16ä¸ªå­å›¾(4x4çŸ©é˜µçš„æ¯ä¸ªå…ƒç´ )
        fig, axs = plt.subplots(4, 4, figsize=(16, 12))
        fig.suptitle(f'Hand-Eye Calibration Results (n={len(Ts)})', fontsize=16)
        
        for i in range(4):
            for j in range(4):
                ax = axs[i, j]
                values = Ts[:, i, j]
                
                # ç»˜åˆ¶æ•°æ®ç‚¹å’Œå¹³å‡çº¿
                ax.plot(values, marker='o', markersize=2, linewidth=0.5, alpha=0.6)
                ax.axhline(T_mean[i, j], color='r', linestyle='--', linewidth=2, label='Mean')
                ax.axhline(T_mean[i, j] + T_std[i, j], color='orange', linestyle=':', alpha=0.5)
                ax.axhline(T_mean[i, j] - T_std[i, j], color='orange', linestyle=':', alpha=0.5)
                
                ax.set_title(f'T[{i},{j}]', fontsize=10)
                ax.set_xlabel('Frame', fontsize=8)
                ax.set_ylabel('Value', fontsize=8)
                ax.grid(True, alpha=0.3)
                ax.legend(fontsize=6)
                
                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                ax.text(0.02, 0.98, f'Î¼={T_mean[i,j]:.4f}\nÏƒ={T_std[i,j]:.4f}',
                       transform=ax.transAxes, fontsize=7,
                       verticalalignment='top',
                       bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))

        plt.tight_layout()
        plt.show()

        # æ‰“å°ç»“æœ
        print("\n" + "="*60)
        print("å¹³å‡ T_cam_base çŸ©é˜µ:")
        print("="*60)
        print(T_mean)
        print("\næ ‡å‡†å·®:")
        print(T_std)
        print("\næœ€å¤§æ ‡å‡†å·®å…ƒç´ : T[{},{}] = {:.6f}".format(
            *np.unravel_index(T_std.argmax(), T_std.shape),
            T_std.max()
        ))
        print("="*60)
        
    except Exception as e:
        print(f"âŒ å¯è§†åŒ–å¤±è´¥: {e}")
        traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    try:
        # é…ç½®å‚æ•°
        repo_id = "collect_data/third_camera"  # æ•°æ®é›†è·¯å¾„
        image_key = "observation.images.side"  # å›¾åƒé”®
        state_key = "observation.state"  # çŠ¶æ€é”®
        tag_size = 0.02  # AprilTagå°ºå¯¸(ç±³)
        tag_id = 0  # AprilTag ID
        batch_size = 500  # æ‰¹æ¬¡å¤§å°(æ ¹æ®å†…å­˜è°ƒæ•´: 100-1000)
        
        # Tagåˆ°æœ«ç«¯æ‰§è¡Œå™¨çš„å›ºå®šå˜æ¢(æ ¹æ®å®é™…å®‰è£…ä¿®æ”¹)
        T_tag_ee = np.eye(4)
        # ä¾‹å¦‚: T_tag_ee[:3, 3] = [0.01, 0.02, 0.03]  # x, y, zåç§»
        
        # å¤„ç†æ•°æ®é›†
        Ts = process_dataset(
            repo_id=repo_id,
            image_key=image_key,
            state_key=state_key,
            tag_size=tag_size,
            tag_id=tag_id,
            T_tag_ee=T_tag_ee,
            batch_size=batch_size
        )
        
        # å¯è§†åŒ–ç»“æœ
        visualize_results(Ts)
        
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸é€€å‡º: {type(e).__name__}: {e}")
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()